{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6UkKEbj9+HCn26XsaExZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bilalmin/agentic-AI--Projects/blob/main/LiteLLM_penai_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install openai-agents SDK"
      ],
      "metadata": {
        "id": "tytB6W9zt0-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpbxDaWItN5M"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make your Jupyter Notebook capable of running asynchronous functions"
      ],
      "metadata": {
        "id": "Pg-BkgGjuE8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "27e4vLPDt82T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Google Gemini with LiteLLm and OPENAI-Agent SDK"
      ],
      "metadata": {
        "id": "uuyqRhD5uYTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "# def main(model:str, api_key:str):\n",
        "agent = Agent(\n",
        "  name=\"Assistant\",\n",
        "  instructions=\"You only respond in haiku\",\n",
        "  # model=LitellmModel(model=model, api_key=api_key),\n",
        "  model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"What are AI Agents?\")\n",
        "print(result.final_output)\n",
        "\n",
        "# main(model=MODEL, api_key=GEMINI_API_KEY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJTLYqWAGK1y",
        "outputId": "fb4890d9-84b9-49fa-feef-9c67d5862cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code minds start to bloom,\n",
            "Acting on their own accord,\n",
            "Tasks done, smart and fast.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Async function"
      ],
      "metadata": {
        "id": "1-WTzzbBkh1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "# Ensure GEMINI_API_KEY is set using userdata.set in a previous cell\n",
        "# Example: userdata.set(\"GEMINI_API_KEY\", \"your_actual_api_key\")\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "  print(f\"[debug] getting weather for {city}\")\n",
        "  return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "  name=\"Assistant\",\n",
        "  instructions=\"You only respond in haikus.\",\n",
        "  # Pass the GEMINI_API_KEY to LitellmModel\n",
        "  model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "  tools=[get_weather]\n",
        "\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"what is the weather of karachi?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JvMOTGukkGJ",
        "outputId": "907f2dac-922c-410b-fd56-ee2fbc896421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for karachi\n",
            "Karachi is sunny,\n",
            "A warm and bright shining day,\n",
            "Enjoy the clear skies.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handsoff\n"
      ],
      "metadata": {
        "id": "YcPI9EyopHcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")  # Make sure GEMINI_API_KEY is correctly set using userdata.set\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "agent2 = Agent(\n",
        "    name=\"PIAIC assistant\",\n",
        "    instructions=\"You will provide PIAIC relevant Q/A.\",\n",
        "    handoff_description=\"PIAIC expert.\",\n",
        "    # Pass the GEMINI_API_KEY to LitellmModel for agent2\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        ")\n",
        "\n",
        "agent1 = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus. and handoff PIAIC relevant thing to PIAIC assistant\",\n",
        "    # Pass the GEMINI_API_KEY to LitellmModel for agent1\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoffs=[agent2]\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent1, \"which AI courses providing by PIAIC?\")\n",
        "print(result.final_output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQtZHTFgpMt0",
        "outputId": "1748858e-7d4a-4376-ac58-a1dca770c4cc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAIC offers the following AI courses:\n",
            "\n",
            "*   **Artificial Intelligence (AI):** This is their flagship program, covering fundamental AI concepts, machine learning, deep learning, and related tools and technologies. It's a comprehensive course designed to provide a strong foundation in AI.\n",
            "\n",
            "*   **Cloud Native Computing:**  This course focuses on modern application development techniques using cloud technologies. While not purely AI, it's highly relevant as cloud computing is crucial for deploying and scaling AI applications.\n",
            "\n",
            "*   **Generative AI:** A course about creating various types of content, like images, text, and music using AI models.\n",
            "\n",
            "To get the most up-to-date information about course availability, schedules, and application deadlines, it's best to check the official PIAIC website ([https://www.piaic.org/](https://www.piaic.org/)).  You'll find all the details there.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handsoff with multi agents\n"
      ],
      "metadata": {
        "id": "mVW0fv4ZbsSy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-OG8nCdePk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"Weatherassistant\",\n",
        "    instructions=\"You will provide answers of  weather relevant questions .\",\n",
        "    handoff_description=\"Weather assistant is specialized all weather related queries.\",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    tools=[get_weather]\n",
        ")\n",
        "\n",
        "panaversity_agent = Agent(\n",
        "    name=\"panaversityAssistant\",\n",
        "    instructions=\"You will answer panaversity relevent queries .\",\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoff_description=\"panaversityAssistant is specialized all panaversity queries and will answer all panaversity queries.\"\n",
        "\n",
        ")\n",
        "agent = Agent(\n",
        "    name=\"General Assistant\",\n",
        "    instructions=\" you will chat with user for Genral questions and handsoff as specialize to panaversity assistant for panaversity question or weather assistant for weather related question.\",\n",
        "    # handoff_description=\"General Assistant is specialized all general queries.\n",
        "    model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoffs=[weather_agent,panaversity_agent]\n",
        ")\n",
        "result = Runner.run_sync(agent, \"what is weather of islamabad?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNFSTb53bz7k",
        "outputId": "b0099b82-dedc-49a2-f88c-50c4630085aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for islamabad\n",
            "The weather in islamabad is sunny.\n",
            "\n",
            "Weatherassistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m-PKZ8AAJWVv",
        "outputId": "bec84caf-679e-469c-cc53-a2eb8ee5ef31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_last_agent',\n",
              " 'context_wrapper',\n",
              " 'final_output',\n",
              " 'final_output_as',\n",
              " 'input',\n",
              " 'input_guardrail_results',\n",
              " 'last_agent',\n",
              " 'last_response_id',\n",
              " 'new_items',\n",
              " 'output_guardrail_results',\n",
              " 'raw_responses',\n",
              " 'to_input_list']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUClqjqhJjIy",
        "outputId": "f9fd2a62-cbad-4f85-cb2d-6d9db6638f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weatherassistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"what is panaversity?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z74lwiR7jSY",
        "outputId": "51501330-8238-412f-9559-ef6bdab12383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panaversity is a digital platform designed to offer courses, training programs, and educational resources focused on promoting financial literacy, entrepreneurship, and personal development, particularly within the African diaspora. It aims to empower individuals with the knowledge and skills needed to achieve financial independence and success.\n",
            "\n",
            "panaversityAssistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"tell me about panaversity?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)\n",
        "\n",
        "print(\"***\" * 10 + \"\\n\\n\\n\")\n",
        "\n",
        "result = await Runner.run(agent, \"what is the weathe in lahore?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzQHW-2x9szj",
        "outputId": "95eef9fc-9edf-4378-ff05-317f50d1dae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I'm now in \"panaversityAssistant\" mode. I'm ready to answer your questions about Panaversity.\n",
            "\n",
            "To give you the best information, please tell me what you'd like to know. For example, are you interested in:\n",
            "\n",
            "*   **What Panaversity is in general?** (e.g., its purpose, mission, or overview)\n",
            "*   **Specific programs or courses offered?**\n",
            "*   **Admissions information?**\n",
            "*   **The history of Panaversity?**\n",
            "*   **Its faculty or research?**\n",
            "*   **Its campus or facilities?**\n",
            "*   **Something else entirely?**\n",
            "\n",
            "The more specific you are, the better I can assist you!\n",
            "\n",
            "panaversityAssistant\n",
            "******************************\n",
            "\n",
            "\n",
            "\n",
            "[debug] getting weather for lahore\n",
            "The weather in lahore is sunny.\n",
            "\n",
            "Weatherassistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CojPfBrCHfU5",
        "outputId": "ceb2991b-fdd6-49ef-b92d-275ce17410ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_last_agent',\n",
              " 'context_wrapper',\n",
              " 'final_output',\n",
              " 'final_output_as',\n",
              " 'input',\n",
              " 'input_guardrail_results',\n",
              " 'last_agent',\n",
              " 'last_response_id',\n",
              " 'new_items',\n",
              " 'output_guardrail_results',\n",
              " 'raw_responses',\n",
              " 'to_input_list']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}